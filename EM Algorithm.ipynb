{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Motivation\n",
    "suppose we have two random variable $x$ and $z$, which follows a joint distribution governed by parmameter $\\theta$. If you know the information of both the $x_i$ and $z_i$ for each individual $i$, then the likelihood function for $x_i$ is \n",
    "$$pr(x=x_i, z=z_i ; \\theta)$$\n",
    "Then you can apply the MLE. Sometime, however, some variables may be lost, say ,$z_i$. We cannot observe the $z_i$. Then, how to deal with this? notice that we have \n",
    "$$pr(x=x_i;\\theta)= \\sum_{z_i}{pr(x=x_i, z=z_i';\\theta)}$$\n",
    "Given this, we can construct the MLE as \n",
    "$$L(\\theta)= \\sum_{i=1}^{N}{\\log{pr(x=x_i;\\theta)}}=\\sum_{i=1}^{N}{\\log{\\sum_{z_i}{pr(x=x_i, z=z_i';\\theta)}}}\\tag{1}$$\n",
    "Here is a question: It is in general very hard to optimize this, since we have the 'log of sum'. If $pr$ itself has some complicated form, then it is even harder to optimize. <b>Therefore, we may want a more viable way to calculate</b>.\n",
    "\n",
    "# Some Maths\n",
    "Notice that we have \n",
    "$$\\sum_{i=1}^{N}{\\log{\\sum_{z_k}{pr(x=x_i, z=z_k;\\theta)}}}=\\sum_{i=1}^{N}{\\log{\\sum_{z_k}{Q(z_k)\\frac{pr(x=x_i, z=z_k;\\theta)}{Q(z_k)}}}}$$\n",
    "$$\\ge \\sum_{i=1}^{N}{Q(z_k)\\sum_{z_k}{\\log{\\frac{pr(x=x_i, z=z_k;\\theta)}{Q(z_k)}}}} \\equiv J(\\theta)$$\n",
    "where we have $\\sum_{z_k}Q(z_k)=1$. The $\\ge$ holds due to the Jensen inequality. From the above reasoning we know that $J(\\theta)$ is a lower bound of $L(\\theta)$.\n",
    "<p>One important thing to notice: if taking $Q(z)$ as given, $J(\\theta)$ is <b> much easier to optimize </b>, since there is only 'sum of log'.Then, how should we find the $Q(z)$? </p>\n",
    "<p> To answer the question, we need to first make clear how to do the optimization. </p>\n",
    "<p>1. Given $\\theta$, for $L(\\theta)$, which is hard to optimize, we want to find out the $Q(z)$ that makes its lower bound, $J(\\theta)$, equals $L(\\theta)$.\n",
    "<p>2. OK, now $L(\\theta)=J(\\theta)$. Therefore, Optimizing $L$ is equivalent to optimizing $J$ ,and optimizing $J$ is easy. Suppose we have (take $Q$ as given!)worked out the optimal $\\theta$ that can maximize $J$. Denote as $\\theta'$.\n",
    "<p>3. Now, given $\\theta'$, we have $L(\\theta')$. Again , we find out the $Q(z)$ that makes $J(\\theta')=L(\\theta')$. We then work out the optimal $\\theta'$ that can maxmize $J(\\theta')$ and denote it as $\\theta''$...\n",
    "<p> We can show that actually this iteration procedure will converge to the optimal point $\\theta^*$.\n",
    "<p>We have constructed the optimization strategy. The last thing to do is to find out $Q$ that can make $J=L$ at each iteration.This is super-simple. We all know that $\\log(\\lambda*a+(1-\\lambda)*b)\\ge \\lambda \\log{a}+(1-\\lambda) \\log{b}$, and the equality holds only when $a=b$. Taking this back to our case, to make $L=J$ we need to have \n",
    "    $$\\frac{pr(x=x_i, z=z_k;\\theta)}{Q(z_k)}=\\frac{pr(x=x_i, z=z_k';\\theta)}{Q(z_k')}$$\n",
    "hold for any $k,k'$. And since $\\sum_{z_k}Q(z_k)=1$, immediately we have\n",
    "    $$Q(z_k)=\\frac{pr(x=x_i, z=z_k;\\theta)}{\\sum_{z_k}{pr(x=x_i, z=z_k;\\theta)}} \\tag{2}$$\n",
    "This is exactly the conditional probability of $z_k$ given we observe $x_i$ and have parameter $\\theta$.\n",
    "    </p>\n",
    "    \n",
    "# Algorithm Summary\n",
    "Now we can finally write the the algorithm. First, guess an initial $\\theta$.\n",
    "<p>step 1: given the $\\theta$, calculate the $Q(z)$ according to (2)\n",
    "<p>step 2: maximize the $L(\\theta)$ in (1) <b>taking all $Q(z)$ as given</b>. get $\\theta'$\n",
    "<p>step 3: if $\\theta'$ is not close to $\\theta$. then let $\\theta=\\theta'$, and repeat from step 1.</p>\n",
    "    https://blog.csdn.net/zouxy09/article/details/8537620"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
